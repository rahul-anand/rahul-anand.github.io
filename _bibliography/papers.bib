---
---


@inproceedings{sharmalumos,
  abbr={USENIX Security},
    pdf={lumos22.pdf},

abstract={Hidden IoT devices are increasingly being used to snoop
on users in hotel rooms or AirBnBs. We envision empowering
users entering such unfamiliar environments to identify and
locate (e.g., hidden camera behind plants) diverse hidden
devices (e.g., cameras, microphones, speakers) using only
their personal handhelds.
What makes this challenging is the limited network visiibility and physical access that a user has in such unfamiliar
environments, coupled with the lack of specialized equipment.

This paper presents Lumos, a system that runs on commmodity user devices (e.g., phone, laptop) and enables users to
identify and locate WiFi-connected hidden IoT devices and
visualize their presence using an augmented reality interface.
Lumos addresses key challenges in: (1) identifying diverse
devices using only coarse-grained wireless layer features,
without IP/DNS layer information and without knowledge
of the WiFi channel assignments of the hidden devices; and
(2) locating the identified IoT devices with respect to the
user using only phone sensors and wireless signal strength
measurements. We evaluated Lumos across 44 different IoT
devices spanning various types, models, and brands across
six different environments. Our results show that Lumos
can identify hidden devices with 95% accuracy and locate
them with a median error of 1.5m within 30 minutes in a
two-bedroom, 1000 sq. ft. apartment},
title = {Lumos: Identifying and Localizing Diverse Hidden {IoT} Devices in an Unfamiliar Environment},
  author={Sharma, Rahul Anand and Soltanaghaei, Elahe and Rowe, Anthony and Sekar, Vyas},
    booktitle={USENIX Security},

    year={2022},
      selected={true},
        preview={lumos.png},



}


@inproceedings{sharma2020all,
abbr={IPSN},
    pdf={glitter20.pdf},
    slides={ipsn_ppt.pdf},

abstract={One of the major challenges faced by Augmented Reality (AR) systems is linking virtual content accurately on physical objects and locations. This problem is amplified for applications like mobile payment, device control or secure pairing that requires authentication. In this paper, we present an active LED tag system called GLITTER that uses a combination of Bluetooth Low-Energy (BLE) and modulated LEDs to anchor AR content with no a priori training or labeling of an environment. Unlike traditional optical markers that encode data spatially, each active optical marker encodes a tagâ€™s identifier by blinking over time, improving both the tag density and range compared to AR tags and QR codes.We show that with a low-power BLE-enabled micro-controller and a single 5 mm LED, we are able to accurately link AR content from potentially hundreds of tags simultaneously on a standard mobile phone from as far as 30 meters. Expanding upon this, using active optical markers as a primitive, we show how a constellation of active optical markers can be used for full 3D pose estimation, which is required for many AR applications, using either a single LED on a planar surface or two or more arbitrarily positioned LEDs. Our design supports 108 unique codes in a single field of view with a detection latency of less than 400 ms even when held by hand.},
  title={All that glitters: Low-power spoof-resilient optical markers for augmented reality},
  author={Sharma, Rahul Anand and Dongare, Adwait and Miller, John and Wilkerson, Nicholas and Cohen, Daniel and Sekar, Vyas and Dutta, Prabal and Rowe, Anthony},
  booktitle={IPSN},
  pages={289--300},
  year={2020},
        selected={true},
                preview={glitter1-PhotoRoom.png},


  organization={IEEE}
}


@inproceedings{sharma2018automated,
  abbr={WACV},
    pdf={wacv18.pdf},

  title={Automated top view registration of broadcast football videos},
  author={Sharma, Rahul Anand and Bhat, Bharath and Gandhi, Vineet and Jawahar, CV},
  booktitle={WACV},
  pages={305--313},
  year={2018},
  organization={IEEE},
        selected={true},

}
@inproceedings{chakraborty2018fall,
  abbr={SenSys},
    pdf={sensys18.pdf},

  title={Fall-curve: A novel primitive for IoT Fault Detection and Isolation},
  author={Chakraborty, Tusher and Nambi, Akshay Uttama and Chandra, Ranveer and Sharma, Rahul and Swaminathan, Manohar and Kapetanovic, Zerina and Appavoo, Jonathan},
  booktitle={SenSys},
  pages={95--107},
  year={2018}
}
@inproceedings{manousis2020contention,
  abbr={SIGCOMM},
    pdf={slomo20.pdf},

  title={Contention-aware performance prediction for virtualized network functions},
  author={Manousis, Antonis and Sharma, Rahul Anand and Sekar, Vyas and Sherry, Justine},
  booktitle={SIGCOMM},
  pages={270--282},
  
  year={2020}
}

@inproceedings{swamy2019low,
abbr={ACM COMPASS},
    pdf={compass19.pdf},

  title={Low-cost aerial imaging for small holder farmers},
  author={Swamy, AN and Kumar, Akshit and Patil, Rohit and Jain, Aditya and Kapetanovic, Zerina and Sharma, Rahul and Vasisht, Deepak and Swaminathan, Manohar and Chandra, Ranveer and Badam, Anirudh and others},
  year={2019},
    booktitle={ACM COMPASS},

}
@article{sharma2017automatic,
  abbr={SIVP},
  
    pdf={sivp18.pdf},

  title={Automatic analysis of broadcast football videos using contextual priors},
  author={Sharma, Rahul Anand and Gandhi, Vineet and Chari, Visesh and Jawahar, CV},
  journal={Signal, Image and Video Processing},
  volume={11},
  number={1},
        selected={true},

  pages={171--178},
  year={2017},
  publisher={Springer}
}
@inproceedings{moon2021accurately,
  abbr={USENIX Security},
    pdf={ampmap21.pdf},

  title={Accurately Measuring Global Risk of Amplification Attacks using $\{$AmpMap$\}$},
  author={Moon, Soo-Jin and Yin, Yucheng and Sharma, Rahul Anand and Yuan, Yifei and Spring, Jonathan M and Sekar, Vyas},
  booktitle={USENIX Security},
  pages={3881--3898},
  year={2021}
}

@inproceedings{soltanaghaei2020robust,
  abbr={BuidSys},
  pdf={buildsys20.pdf},

  title={Robust and practical WiFi human sensing using on-device learning with a domain adaptive model},
  author={Soltanaghaei, Elahe and Sharma, Rahul Anand and Wang, Zehao and Chittilappilly, Adarsh and Luong, Anh and Giler, Eric and Hall, Katie and Elias, Steve and Rowe, Anthony},
  booktitle={BuildSys},
  pages={150--159},
  year={2020}
}
@inproceedings{sharma2015fine,
  abbr={ACPR},
  pdf={acpr15.pdf},

  title={Fine-grain annotation of cricket videos},
  author={Sharma, Rahul Anand and Sankar, K Pramod and Jawahar, CV},
        selected={true},

  booktitle={ACPR},
  pages={421--425},
  year={2015},
  organization={IEEE}
}
@inproceedings{saraogi2016event,
  abbr={ICVGIP},
  pdf={icvgip16.pdf},

  title={Event recognition in broadcast soccer videos},
  author={Saraogi, Himangi and Sharma, Rahul Anand and Kumar, Vijay},
  booktitle={ICVGIP},
  pages={1--7},
  year={2016}
}
@article{sharma2018learnability,
abbr={Arxiv},
  pdf={learning18.pdf},

  title={Learnability of learned neural networks},
        selected={true},

  author={Sharma, Rahul Anand and Goyal, Navin and Choudhury, Monojit and Netrapalli, Praneeth},
  year={2018}
}

